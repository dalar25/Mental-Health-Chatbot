{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2ar1w-bud2W"
      },
      "source": [
        "#Bringing the Chatbot to 2020: Introducing the State of the Art (SOTA) in Machine Learning and Applying it to Chatbots\n",
        "\n",
        "In our previous notebook, we looked at how neural networks can be used in the context of speech recognition and chatbots. We studied how we can model text using recurrent neural networks (RNNs) and long short term memory networks (LSTMs) to predict, for example, what words will come next in a conversation.\n",
        "\n",
        "Would it surprise you to know that we can actually do much better than RNNs and LSTMs today? Today's cutting edge technology relies on more advanced neural networks that build on top of what RNNs and LSTMs discovered, ushering in a new era of natural language processing!\n",
        "\n",
        "In this notebook, we'll dive into the state of the art in NLP and look at how we can use that to help create our mental health chatbot. Like before, we'll train our neural network, then create an interface that'll allow us to see how well our new chatbot is doing. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPWZy5PcmQz6"
      },
      "source": [
        "###Outline:\n",
        "\n",
        "This'll be the outline for today's notebook\n",
        "\n",
        "1. Introduction to Transformers\n",
        "2. Let's create our own Transformer!\n",
        "2. Exploring and initializing our chat dataset\n",
        "4. Training our Transformer on our data and using pre-trained models\n",
        "5. Can we do better? An introduction to transfer learning\n",
        "6. What does this mean? Where do we go from here?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cV2aUgoEtbG"
      },
      "source": [
        "###**Important: Before starting, set your runtype type to GPU!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nWaFN4hB9C-",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "851616c8-6e04-45a6-8929-4d03cbd6e3ee"
      },
      "source": [
        "#@title Run this cell to install our libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import spacy\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "tf.random.set_seed(1)\n",
        "import os\n",
        "\n",
        "# set pandas viewing options\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option(\"max_colwidth\", None)\n",
        "#pd.reset_option(\"max_colwidth\")\n",
        "\n",
        "# the source of our data is: https://github.com/nbertagnolli/counsel-chat\n",
        "\n",
        "# load pretrained weights:\n",
        "# import gdown \n",
        "# gdown.download('https://drive.google.com/uc?export=download&id=1rR0HAOKgs0yGAyZwqeJkX1U3W8234BgR','chatbot_transformer_v4.h5',True);\n",
        "!wget 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Mental%20Health%20Chatbots/chatbot_transformer_v4.h5'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-12 03:03:29--  https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Mental%20Health%20Chatbots/chatbot_transformer_v4.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.152.128, 173.194.195.128, 173.194.198.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.152.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 37056308 (35M) [application/octet-stream]\n",
            "Saving to: ‘chatbot_transformer_v4.h5’\n",
            "\n",
            "chatbot_transformer 100%[===================>]  35.34M  64.0MB/s    in 0.6s    \n",
            "\n",
            "2022-03-12 03:03:29 (64.0 MB/s) - ‘chatbot_transformer_v4.h5’ saved [37056308/37056308]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChTcJrbVG0R-"
      },
      "source": [
        "##Introduction to Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIXQPJnzD6Cq"
      },
      "source": [
        "###The Rise of the Transformers\n",
        "\n",
        "In 2017, researchers from Google introduced a ground-breaking new approach to the field of natural language processing (NLP).\n",
        "\n",
        "> **Why not teach a neural network to figure out what words it should pay attention to?**\n",
        "\n",
        "They developed a model to do just that, which we call **transformers**. Since then, transformers have revolutionized NLP, with transformer-based architectures such as [**GPT-2**](https://en.wikipedia.org/wiki/OpenAI#GPT-2) and [**GPT-3**](https://en.wikipedia.org/wiki/GPT-3) producing ground-breaking results. In this section, we'll explore what a transformer is and how it enables neural networks to figure out what words it should pay attention to.\n",
        "\n",
        "**Optional**: Read [their original paper on transformers](https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf). While the details may be complex, skimming papers for key information is a good habit to develop!\n",
        "\n",
        "**Optional**: Watch [this YouTube video](https://www.youtube.com/watch?v=4Bdc55j80l8) for a detailed overview on transformers.\n",
        "\n",
        "**Optional**: For a bit of more light-hearted fun, try out [AI Dungeon](https://play.aidungeon.io/main/home), an impressive text role-playing game created using GPT-3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW8KnjiaEhT4"
      },
      "source": [
        "###What does it mean for a machine to pay attention?\n",
        "\n",
        "To illustrate what it means for a machine to pay attention, let's look at the following example:\n",
        "\n",
        "> *The animal didn't cross the street because it was too tired.*\n",
        "\n",
        "**Question**: In this sentence, what is **it** referring to?\n",
        "\n",
        "Now, look at this example:\n",
        "\n",
        "> *The animal didn't cross the street because it was too wide.*\n",
        "\n",
        "**Question**: In *this* sentence, what is **it** referring to?\n",
        "\n",
        "Now, let's think about how we might program a computer to accomplish this task.\n",
        "\n",
        "**Question**: Could we hard-code rules to accomplish this task? If so, what would such rules look like? What might be some problems or difficulties with this approach (if any)?\n",
        "\n",
        "**Question**: Could we use an RNN to accomplish this task? If so, how should we set up this RNN? What might be some problems or difficulties with this approach (if any)?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8oC0lle1j_E"
      },
      "source": [
        "Transformers were revolutionary because they enable computers to consider the *entire* conversation at once when guessing what semi-ambiguous words such as **it** refer to. We'll explore step-by-step how exactly transformers accomplish this task by implementing a transformer-based architecture for our chatbot and exploring its properties!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQL6TMP2F9bM"
      },
      "source": [
        "##Let's create our own Transformer!\n",
        "\n",
        "**Note**: We invite you to ask lots of questions as you complete this project! This is the brand-new, cutting-edge in AI and ML, so it's stuff that's relatively new even to instructors!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQ6kBZovDo7Z"
      },
      "source": [
        "###Attention\n",
        "\n",
        "Remember that what made Transformers unique was their ability to pay attention!.\n",
        "\n",
        "What does this mean? \n",
        "\n",
        "Let's look at a demonstration: \n",
        "\n",
        "![link](https://raw.githubusercontent.com/jessevig/bertviz/master/images/head_thumbnail_right.gif)\n",
        "\n",
        "If you look at this demo, the Transformer scans through each word in the left column and figures out what words in the sentence are most relevant to that word. The darker the color of the blue box on the right, the more the program thinks that word is relevant to the grey word. For example, when the grey box is on \"rabbit\", you should see that the word \"hopped\" on the right is highlighted in dark blue. Here, as the Transformer scans through each word on the left, it looks at the other words in the sentence and sees if, based on the other words and where they are in the sentence, if it can figure out what word should come next.\n",
        "\n",
        "This is how the Transformer learns what words it should be paying attention to, and we'll create this in the code chunks below!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UOpvQNXFWhW"
      },
      "source": [
        "###Multi-Headed Attention\n",
        "Transformers take the \"Attention\" process further by using something called **\"Multi-Headed Attention\"**\n",
        "\n",
        "What does this mean?\n",
        "\n",
        "Intuitively, it means that the model is taking several different looks at the input data. It's similar to how, for example, if you look at a painting from a different angle or if you look at a building during a different time of day, you might get a different view. \n",
        "\n",
        "Imagine if this dog were paying attention to you:\n",
        "\n",
        "![link](http://vignette2.wikia.nocookie.net/naruto/images/5/5a/Multi_headed_dog2.PNG/revision/latest?cb=20150209111333)\n",
        "\n",
        "Each head of the dog is paying attention to you, but each head gets a slightly different view of you. \n",
        "\n",
        "In the same way, Transformers use several \"heads\" to pay attention to the data in different ways, learning slightly different patterns with each head. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzYMZYuSDe5G"
      },
      "source": [
        "Looks complicated? Don't worry, we'll simplify it for our you! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNHAdT_iCMOc",
        "cellView": "form"
      },
      "source": [
        "#@title Run to get our function for calculating \"attention\"\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  \"\"\"Calculate the attention weights. \"\"\"\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  # scale matmul_qk\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # add the mask to zero out padding tokens\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  # softmax is normalized on the last axis (seq_len_k)\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  output = tf.matmul(attention_weights, value)\n",
        "\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srAlGpjHE72c",
        "cellView": "form"
      },
      "source": [
        "#@title Run this to create the multi-head attention mechanism\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # linear layers\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    # scaled dot-product attention\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    # concatenation of heads\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    # final linear layer\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcsfWqDFRZDJ"
      },
      "source": [
        "####Masking\n",
        "\n",
        "Remember how we used padding to add `<pad>` to fill in sentences that were too short? We don't want our model to think that `<pad>` is an actual word (they're only there as placeholders), so we'll use something called a **mask**, which will cover up the `\"<pad>\"` instances in our sequence so that our model ignores them. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvhIjJ4dHoU_",
        "cellView": "form"
      },
      "source": [
        "#@title Run this chunk to create the masks\n",
        "def create_padding_mask(x):\n",
        "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
        "  # (batch_size, 1, 1, sequence length)\n",
        "  return mask[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "#print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))\n",
        "\n",
        "def create_look_ahead_mask(x):\n",
        "  seq_len = tf.shape(x)[1]\n",
        "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
        "  padding_mask = create_padding_mask(x)\n",
        "  return tf.maximum(look_ahead_mask, padding_mask)\n",
        "\n",
        "#print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEwQvQR3Jteo",
        "cellView": "form"
      },
      "source": [
        "#@title Run this chunk as well, for more processing\n",
        "\n",
        "# note: this gives positional information (i.e., where the words are in a sentence\n",
        "# and includes it in the model) since our model isn't recurrent anymore\n",
        "\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "    # apply sin to even index in the array\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # apply cos to odd index in the array\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
        "\n",
        "# example of this class: \n",
        "\n",
        "#sample_pos_encoding = PositionalEncoding(50, 512)\n",
        "\n",
        "#plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0], cmap='RdBu')\n",
        "#plt.xlabel('Depth')\n",
        "#plt.xlim((0, 512))\n",
        "#plt.ylabel('Position')\n",
        "#plt.colorbar()\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FH6-HXYSSjnP"
      },
      "source": [
        "###Encoders\n",
        "\n",
        "Remember encoders from last notebook? They were used to process the inputs and then fed those processed inputs into the decoder. We feed in our patient questions into the encoder, the encoder figures out \"the gist\" of the patient's question, and then feeds that into the decoder for it to respond appropriately (in this case, predict the appropriate therapist response). \n",
        "\n",
        "For our Transformer model, we take all the steps above (Multi-Headed Attention and masking) and combine them into a series of layers, which will make up our encoder. Our input into this encoder is going to be our patient questions, and the output of our encoder (and, subsequently, the input to our decoder) will be a matrix (think of it like an Excel table) that has each word, weighed by \"how important\" it is in the context of the entire sentence (which gives us a measure of how much the model should \"pay attention\" to that word). \n",
        "\n",
        "Run the code chunks below to create our encoders!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8jGQcv4OzBX",
        "cellView": "form"
      },
      "source": [
        "#@title Let's create our encoder!\n",
        "# individual encoder layer\n",
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
        "\n",
        "# complete encoder architecture\n",
        "def encoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bx_P5wF4VvmN"
      },
      "source": [
        "###Decoders\n",
        "\n",
        "Now that we've created our encoder, we need to create the decoder as well. The purpose of the decoder is to take what the encoder spits out and \"decode\" it into something that's useful (in our case, a therapist's response). For Transformers, the Decoder will look very similar to our Encoder since it also uses multi-headed attention.\n",
        "\n",
        "The end goal of the Decoder is to figure out how the patient's question relates to what the therapist's response was. It takes the output of the Encoder step, which essentially tells it how much \"attention\" should be placed on each word in the patient's question, and from there learns what a therapist would normally say in that situation. \n",
        "\n",
        "Run the code chunk below to create our decoders!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmaq4ZBiSWdc",
        "cellView": "form"
      },
      "source": [
        "#@title Let's create our decoder!\n",
        "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "\n",
        "  attention1 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': look_ahead_mask\n",
        "      })\n",
        "  attention1 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention1 + inputs)\n",
        "\n",
        "  attention2 = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
        "          'query': attention1,\n",
        "          'key': enc_outputs,\n",
        "          'value': enc_outputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
        "  attention2 = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention2 + attention1)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(outputs + attention2)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)\n",
        "\n",
        "# decoder itself\n",
        "def decoder(vocab_size,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            name='decoder'):\n",
        "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
        "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
        "  look_ahead_mask = tf.keras.Input(\n",
        "      shape=(1, None, None), name='look_ahead_mask')\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
        "  \n",
        "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
        "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = decoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name='decoder_layer_{}'.format(i),\n",
        "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
        "      outputs=outputs,\n",
        "      name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqXFKEWtYO4m"
      },
      "source": [
        "###Putting it all together!\n",
        "\n",
        "Now that we have our encoder and decoder, let's combine them into one model, our Transformer model!\n",
        "\n",
        "Run the code chunk below to create our Transformer model!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNoHySCeWl2e",
        "cellView": "form"
      },
      "source": [
        "#@title Let's create our Transformer!\n",
        "def transformer(vocab_size,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
        "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
        "\n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(inputs)\n",
        "  # mask the future tokens for decoder inputs at the 1st attention block\n",
        "  look_ahead_mask = tf.keras.layers.Lambda(\n",
        "      create_look_ahead_mask,\n",
        "      output_shape=(1, None, None),\n",
        "      name='look_ahead_mask')(dec_inputs)\n",
        "  # mask the encoder outputs for the 2nd attention block\n",
        "  dec_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='dec_padding_mask')(inputs)\n",
        "\n",
        "  enc_outputs = encoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  dec_outputs = decoder(\n",
        "      vocab_size=vocab_size,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPdViy2zCL2p"
      },
      "source": [
        "Awesome! Now that we've finished creating our Transformer model, let's use it to create a start of the art chatbot!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUUBAG5OChlX"
      },
      "source": [
        "## Preparing our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjDbmBt0qYF0",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to download our dataset\n",
        "\n",
        "# load in our data with this code chunk: \n",
        "chat_data = pd.read_csv(\"https://raw.githubusercontent.com/nbertagnolli/counsel-chat/master/data/20200325_counsel_chat.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkoh0dumRDtH"
      },
      "source": [
        "We will use the same dataset as last time. As a recap, our dataset contains questions and answers taken from conversations between patients and licensed mental health professionals.\n",
        "\n",
        "**Disclaimer**: Once again, this dataset was made freely available and all data was provided consensually, and in anonymized form. Remember, when working with sensitive data such as medical data, you should *always* get permission first!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0IsLpf3h7rU"
      },
      "source": [
        "### Exploring our data\n",
        "\n",
        "As usual, let's begin by exploring our data. Our data is in a pandas dataframe named `chat_data`.\n",
        "\n",
        "**Exercise**: Print out the first 5 rows in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYJAKu5Nh9Sv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8aa2090b-204b-4304-d62c-27716598465f"
      },
      "source": [
        "## YOUR CODE HERE\n",
        "chat_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  questionID  \\\n",
              "0           0           0   \n",
              "1           1           0   \n",
              "2           2           0   \n",
              "3           3           0   \n",
              "4           4           0   \n",
              "\n",
              "                                             questionTitle  \\\n",
              "0  Can I change my feeling of being worthless to everyone?   \n",
              "1  Can I change my feeling of being worthless to everyone?   \n",
              "2  Can I change my feeling of being worthless to everyone?   \n",
              "3  Can I change my feeling of being worthless to everyone?   \n",
              "4  Can I change my feeling of being worthless to everyone?   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                 questionText  \\\n",
              "0  I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone?   \n",
              "1  I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone?   \n",
              "2  I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone?   \n",
              "3  I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone?   \n",
              "4  I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone?   \n",
              "\n",
              "                                                                               questionLink  \\\n",
              "0  https://counselchat.com/questions/can-i-change-my-feeling-of-being-worthless-to-everyone   \n",
              "1  https://counselchat.com/questions/can-i-change-my-feeling-of-being-worthless-to-everyone   \n",
              "2  https://counselchat.com/questions/can-i-change-my-feeling-of-being-worthless-to-everyone   \n",
              "3  https://counselchat.com/questions/can-i-change-my-feeling-of-being-worthless-to-everyone   \n",
              "4  https://counselchat.com/questions/can-i-change-my-feeling-of-being-worthless-to-everyone   \n",
              "\n",
              "        topic  \\\n",
              "0  depression   \n",
              "1  depression   \n",
              "2  depression   \n",
              "3  depression   \n",
              "4  depression   \n",
              "\n",
              "                                                                               therapistInfo  \\\n",
              "0                                        Sherry Katz, LCSWCouples and Family Therapist, LCSW   \n",
              "1                      Robin Landwehr, DBH, LPCC, NCCMental Health in a Primary Care Setting   \n",
              "2    Lee KingI use an integrative approach to treatment and have an online therapy practice.   \n",
              "3  Shauntai Davis-YearginPersonalized, private online counseling for individuals and couples   \n",
              "4                                    Jordan WhiteLicensed Social Worker at Oak Roots Dynamic   \n",
              "\n",
              "                                                     therapistURL  \\\n",
              "0             https://counselchat.com/therapists/sherry-katz-lcsw   \n",
              "1  https://counselchat.com/therapists/robin-landwehr-dbh-lpcc-ncc   \n",
              "2                     https://counselchat.com/therapists/lee-king   \n",
              "3       https://counselchat.com/therapists/shauntai-davis-yeargin   \n",
              "4                 https://counselchat.com/therapists/jordan-white   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           answerText  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   If everyone thinks you're worthless, then maybe you need to find new people to hang out with.Seriously, the social context in which a person lives is a big influence in self-esteem.Otherwise, you can go round and round trying to understand why you're not worthless, then go back to the same crowd and be knocked down again.There are many inspirational messages you can find in social media.  Maybe read some of the ones which state that no person is worthless, and that everyone has a good purpose to their life.Also, since our culture is so saturated with the belief that if someone doesn't feel good about themselves that this is somehow terrible.Bad feelings are part of living.  They are the motivation to remove ourselves from situations and relationships which do us more harm than good.Bad feelings do feel terrible.   Your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today.   \n",
              "1  Hello, and thank you for your question and seeking advice on this. Feelings of worthlessness is unfortunately common. In fact, most people, if not all, have felt this to some degree at some point in their life. You are not alone. Changing our feelings is like changing our thoughts - it's hard to do. Our minds are so amazing that the minute you change your thought another one can be right there to take it's place. Without your permission, another thought can just pop in there. The new thought may feel worse than the last one! My guess is that you have tried several things to improve this on your own even before reaching out on here. People often try thinking positive thoughts, debating with their thoughts, or simply telling themselves that they need to \"snap out of it\" - which is also a thought that carries some self-criticism. Some people try a different approach, and there are counselors out there that can help you with this. The idea is that instead of trying to change the thoughts, you change how you respond to them. You learn skills that allow you to manage difficult thoughts and feelings differently so they don't have the same impact on you that they do right now. For some people, they actually DO begin to experience less hurtful thoughts once they learn how to manage the ones they have differently. Acceptance and Commitment Therapy may be a good choice for you. There is information online and even self-help books that you can use to teach you the skills that I mentioned. Because they are skills, they require practice, but many people have found great relief and an enriched life by learning them. As for suicidal thoughts, I am very glad to read that this has not happened to you. Still, you should watch out for this because it can be a sign of a worsening depression. If you begin to think about this, it is important to reach out to a support system right away. The National Suicide Prevention Lifeline is 1-800-273-8255. The text line is #741741. I hope some other colleagues will provide you more suggestions. Be well...Robin Landwehr, DBH, LPCC   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         First thing I'd suggest is getting the sleep you need or it will impact how you think and feel. I'd look at finding what is going well in your life and what you can be grateful for. I believe everyone has talents and wants to find their purpose in life. I think you can figure it out with some help.   \n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Therapy is essential for those that are feeling depressed and worthless. When I work with those that are experiencing concerns related to feeling of depression and issues with self esteem. I generally work with my client to help build coping skills to reduce level of depression and to assist with strengthening  self esteem, by guiding my client with CBT practices. CBT helps with gaining a better awareness of how your thought process influences your belief system, and how your beliefs impact your actions and the outcome of your behaviors.  This process isn’t easy but it helps teach an individual that we don’t always have control over what happens in our lives but we can control how we interpret, feel, and behave. CBT is good for individuals dealing with depression, anxiety, toxic relationships, stress, self esteem, codependency, etc.   \n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   I first want to let you know that you are not alone in your feelings and there is always someone there to help. You can always change your feelings and change your way of thinking by being open to trying to change. You can always make yourself available to learning new things or volunteering so that you can make a purpose for yourself.   \n",
              "\n",
              "   upvotes  views  split  \n",
              "0        1   2899  train  \n",
              "1        1   3514  train  \n",
              "2        0      5  train  \n",
              "3        0     31  train  \n",
              "4        0    620  train  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f52878ab-d2d7-4be9-856f-3327f39b6f76\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>questionID</th>\n",
              "      <th>questionTitle</th>\n",
              "      <th>questionText</th>\n",
              "      <th>questionLink</th>\n",
              "      <th>topic</th>\n",
              "      <th>therapistInfo</th>\n",
              "      <th>therapistURL</th>\n",
              "      <th>answerText</th>\n",
              "      <th>upvotes</th>\n",
              "      <th>views</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Can I change my feeling of being worthless to everyone?</td>\n",
              "      <td>I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone?</td>\n",
              "      <td>https://counselchat.com/questions/can-i-change-my-feeling-of-being-worthless-to-everyone</td>\n",
              "      <td>depression</td>\n",
              "      <td>Sherry Katz, LCSWCouples and Family Therapist, LCSW</td>\n",
              "      <td>https://counselchat.com/therapists/sherry-katz-lcsw</td>\n",
              "      <td>If everyone thinks you're worthless, then maybe you need to find new people to hang out with.Seriously, the social context in which a person lives is a big influence in self-esteem.Otherwise, you can go round and round trying to understand why you're not worthless, then go back to the same crowd and be knocked down again.There are many inspirational messages you can find in social media.  Maybe read some of the ones which state that no person is worthless, and that everyone has a good purpose to their life.Also, since our culture is so saturated with the belief that if someone doesn't feel good about themselves that this is somehow terrible.Bad feelings are part of living.  They are the motivation to remove ourselves from situations and relationships which do us more harm than good.Bad feelings do feel terrible.   Your feeling of worthlessness may be good in the sense of motivating you to find out that you are much better than your feelings today.</td>\n",
              "      <td>1</td>\n",
              "      <td>2899</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Can I change my feeling of being worthless to everyone?</td>\n",
              "      <td>I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone?</td>\n",
              "      <td>https://counselchat.com/questions/can-i-change-my-feeling-of-being-worthless-to-everyone</td>\n",
              "      <td>depression</td>\n",
              "      <td>Robin Landwehr, DBH, LPCC, NCCMental Health in a Primary Care Setting</td>\n",
              "      <td>https://counselchat.com/therapists/robin-landwehr-dbh-lpcc-ncc</td>\n",
              "      <td>Hello, and thank you for your question and seeking advice on this. Feelings of worthlessness is unfortunately common. In fact, most people, if not all, have felt this to some degree at some point in their life. You are not alone. Changing our feelings is like changing our thoughts - it's hard to do. Our minds are so amazing that the minute you change your thought another one can be right there to take it's place. Without your permission, another thought can just pop in there. The new thought may feel worse than the last one! My guess is that you have tried several things to improve this on your own even before reaching out on here. People often try thinking positive thoughts, debating with their thoughts, or simply telling themselves that they need to \"snap out of it\" - which is also a thought that carries some self-criticism. Some people try a different approach, and there are counselors out there that can help you with this. The idea is that instead of trying to change the thoughts, you change how you respond to them. You learn skills that allow you to manage difficult thoughts and feelings differently so they don't have the same impact on you that they do right now. For some people, they actually DO begin to experience less hurtful thoughts once they learn how to manage the ones they have differently. Acceptance and Commitment Therapy may be a good choice for you. There is information online and even self-help books that you can use to teach you the skills that I mentioned. Because they are skills, they require practice, but many people have found great relief and an enriched life by learning them. As for suicidal thoughts, I am very glad to read that this has not happened to you. Still, you should watch out for this because it can be a sign of a worsening depression. If you begin to think about this, it is important to reach out to a support system right away. The National Suicide Prevention Lifeline is 1-800-273-8255. The text line is #741741. I hope some other colleagues will provide you more suggestions. Be well...Robin Landwehr, DBH, LPCC</td>\n",
              "      <td>1</td>\n",
              "      <td>3514</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Can I change my feeling of being worthless to everyone?</td>\n",
              "      <td>I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone?</td>\n",
              "      <td>https://counselchat.com/questions/can-i-change-my-feeling-of-being-worthless-to-everyone</td>\n",
              "      <td>depression</td>\n",
              "      <td>Lee KingI use an integrative approach to treatment and have an online therapy practice.</td>\n",
              "      <td>https://counselchat.com/therapists/lee-king</td>\n",
              "      <td>First thing I'd suggest is getting the sleep you need or it will impact how you think and feel. I'd look at finding what is going well in your life and what you can be grateful for. I believe everyone has talents and wants to find their purpose in life. I think you can figure it out with some help.</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>Can I change my feeling of being worthless to everyone?</td>\n",
              "      <td>I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone?</td>\n",
              "      <td>https://counselchat.com/questions/can-i-change-my-feeling-of-being-worthless-to-everyone</td>\n",
              "      <td>depression</td>\n",
              "      <td>Shauntai Davis-YearginPersonalized, private online counseling for individuals and couples</td>\n",
              "      <td>https://counselchat.com/therapists/shauntai-davis-yeargin</td>\n",
              "      <td>Therapy is essential for those that are feeling depressed and worthless. When I work with those that are experiencing concerns related to feeling of depression and issues with self esteem. I generally work with my client to help build coping skills to reduce level of depression and to assist with strengthening  self esteem, by guiding my client with CBT practices. CBT helps with gaining a better awareness of how your thought process influences your belief system, and how your beliefs impact your actions and the outcome of your behaviors.  This process isn’t easy but it helps teach an individual that we don’t always have control over what happens in our lives but we can control how we interpret, feel, and behave. CBT is good for individuals dealing with depression, anxiety, toxic relationships, stress, self esteem, codependency, etc.</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>Can I change my feeling of being worthless to everyone?</td>\n",
              "      <td>I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contemplated suicide. I've always wanted to fix my issues, but I never get around to it.\\n   How can I change my feeling of being worthless to everyone?</td>\n",
              "      <td>https://counselchat.com/questions/can-i-change-my-feeling-of-being-worthless-to-everyone</td>\n",
              "      <td>depression</td>\n",
              "      <td>Jordan WhiteLicensed Social Worker at Oak Roots Dynamic</td>\n",
              "      <td>https://counselchat.com/therapists/jordan-white</td>\n",
              "      <td>I first want to let you know that you are not alone in your feelings and there is always someone there to help. You can always change your feelings and change your way of thinking by being open to trying to change. You can always make yourself available to learning new things or volunteering so that you can make a purpose for yourself.</td>\n",
              "      <td>0</td>\n",
              "      <td>620</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f52878ab-d2d7-4be9-856f-3327f39b6f76')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f52878ab-d2d7-4be9-856f-3327f39b6f76 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f52878ab-d2d7-4be9-856f-3327f39b6f76');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zZ3_r44os0v"
      },
      "source": [
        "**Question**: What does each row in our dataset represent?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym79-d_QodH2"
      },
      "source": [
        "Now, let's set our `X` and `y` variables to be, respectively, the input and output for our chatbot.\n",
        "\n",
        "**Question**: What should we set `X` to be? What should we set `y` to be?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3CEuQ9Wgix_"
      },
      "source": [
        "X = chat_data[\"questionTitle\"] ## YOUR CODE HERE\n",
        "y = chat_data[\"answerText\"] ## YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCBLRWFXscLv"
      },
      "source": [
        "### Cleaning our data\n",
        "\n",
        "Before we can begin to use our data, we must preprocess it to clean up any data which we don't want to see. Run the following cell to perform some initial cleaning of our data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2tzKvtdIDyF",
        "cellView": "both"
      },
      "source": [
        "def preprocess_text(phrase): \n",
        "  phrase = re.sub(r\"\\xa0\", \"\", phrase) # removes \"\\xa0\"\n",
        "  phrase = re.sub(r\"\\n\", \"\", phrase) # removes \"\\n\"\n",
        "  phrase = re.sub(\"[.]{1,}\", \".\", phrase) # removes duplicate \".\"s\n",
        "  phrase = re.sub(\"[ ]{1,}\", \" \", phrase) # removes duplicate spaces\n",
        "  return phrase\n",
        "\n",
        "# run cleaning function\n",
        "X = X.apply(preprocess_text)\n",
        "y = y.apply(preprocess_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR_RtmzXtiGo"
      },
      "source": [
        "### Splitting up our questions and answers\n",
        "\n",
        "There's a little more preprocessing we need to do however! We want to keep our phrases relatively short; however, some of the questions and answers in our dataset are several sentences long.\n",
        "\n",
        "To solve this problem, we'll split up each question and each answer into their constituent sentences. We'll then pair the first sentence of the question with the first sentence of the answer, the second sentence of the question with the second sentence of the answer, and so on until we can't form any more pairs.\n",
        "\n",
        "For example, suppose we have the following question-answer pair:\n",
        "> **Q**: \"I am not feeling well today. I feel sad.\"\n",
        "\n",
        "> **A**: \"Tell me more about how you feel. What have you been up to today?\"\n",
        "\n",
        "First, we would split up the question into its constituent sentences, resulting in `[\"I am not feeling well today.\", \"I feel sad.\"]`. Similarly, we would split up the answer into its constituent sentences, resulting in `[\"Tell me more about how you feel.\", \"What have you been up to today?\"]`. Finally, we would pair each sentence of the question with its corresponding sentence of the answer, ultimately resulting in two separate question-answer pairs:\n",
        "> **Q**: \"I am not feeling well today.\"\n",
        "\n",
        "> **A**: \"Tell me more about how you feel.\"\n",
        "\n",
        "and\n",
        "\n",
        "> **Q**: \"I feel sad.\"\n",
        "\n",
        "> **A**: \"What have you been up to today?\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-xAv6clejp_"
      },
      "source": [
        "# run this code chunk, to store all of our question/answer pairs\n",
        "question_answer_pairs = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I7FZuEAdVu_",
        "cellView": "both"
      },
      "source": [
        "# loop through each combination of question + answer\n",
        "for (question, answer) in zip(X, y):\n",
        "\n",
        "  # clean up text inputs\n",
        "\n",
        "  # example: \n",
        "  # question = \"I am not feeling well today. I feel sad.\"\n",
        "  # answer = \"Tell me more about how you feel. What have you been up to today?\"\n",
        "\n",
        "  question = preprocess_text(question) \n",
        "  answer = preprocess_text(answer)\n",
        "\n",
        "  # split by .\n",
        "  # example\n",
        "  # question_arr = [\"I am not feeling well today\", \"I feel sad\"]\n",
        "  # answer_arr = [\"Tell me more about how you feel\", \"What have you been up to?\"]\n",
        "  question_arr = question.split(\".\")\n",
        "  answer_arr = answer.split(\".\")\n",
        "\n",
        "  # get the maximum length, which will be the shorter of the two\n",
        "  max_sentences = min(len(question_arr), len(answer_arr))\n",
        "\n",
        "  # for each combination of question + answer, pair them up\n",
        "  for i in range(max_sentences):\n",
        "\n",
        "    # set up Q/A pair\n",
        "    q_a_pair = []\n",
        "\n",
        "    # append question, answer to pair (e.g,. first sentence of question + first sentence of answer, etc.)\n",
        "    q_a_pair.append(question_arr[i])\n",
        "    q_a_pair.append(answer_arr[i])\n",
        "\n",
        "    # append to question_answer_pairs\n",
        "    question_answer_pairs.append(q_a_pair)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8m_GUzhLgYM"
      },
      "source": [
        "### Tokenizing and padding our data\n",
        "\n",
        "The next preprocessing steps that we need to implement are going to be tokenization and padding (which we reviewed in our last notebook). If you recall, tokenization is the process of turning a sentence into an array of the individual words (aka tokens), while padding is a way to add \"filler\" to make short sentences the same length as long sentences. Now that we've seen how tokenization and padding work, let's actually implement that on our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4CbtUGS7dNf"
      },
      "source": [
        "#@title Run this cell to tokenize our data\n",
        "\n",
        "# Build tokenizer using tfds for both questions and answers\n",
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
        "    [arr[0] + arr[1] for arr in question_answer_pairs], target_vocab_size=2**13)\n",
        "\n",
        "# Define start and end token to indicate the start and end of a sentence\n",
        "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
        "\n",
        "# Vocabulary size plus start and end token\n",
        "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skfHWsGWuPkT",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to define our tokenization and padding functions!\n",
        "\n",
        "# maximum sentence length\n",
        "MAX_LENGTH = 100 # chosen arbitrarily\n",
        "\n",
        "# tokenize, filter, pad sentences\n",
        "def tokenize_and_filter(inputs, outputs):\n",
        "  \"\"\"\n",
        "    Tokenize, filter, and pad our inputs and outputs\n",
        "  \"\"\"\n",
        "\n",
        "  # store results\n",
        "  tokenized_inputs, tokenized_outputs = [], []\n",
        "\n",
        "  # loop through inputs, outputs\n",
        "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
        "\n",
        "    # tokenize sentence\n",
        "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
        "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
        "    \n",
        "    # check tokenized sentence max length\n",
        "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
        "      tokenized_inputs.append(sentence1)\n",
        "      tokenized_outputs.append(sentence2)\n",
        "\n",
        "  # pad tokenized sentences\n",
        "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_inputs, maxlen = MAX_LENGTH, padding = \"post\")\n",
        "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "      tokenized_outputs, maxlen = MAX_LENGTH, padding = \"post\")\n",
        "    \n",
        "  return tokenized_inputs, tokenized_outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dnCQ0dfxnbO",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to run tokenization and padding on our dataset\n",
        "# get questions, answers\n",
        "questions, answers = tokenize_and_filter([arr[0] for arr in question_answer_pairs], \n",
        "                                         [arr[1] for arr in question_answer_pairs])\n",
        "\n",
        "print('Vocab size: {}'.format(VOCAB_SIZE))\n",
        "print('Number of samples: {}'.format(len(questions)))\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 20000\n",
        "\n",
        "# decoder inputs use the previous target as input\n",
        "# remove START_TOKEN from targets\n",
        "dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    {\n",
        "        'inputs': questions,\n",
        "        'dec_inputs': answers[:, :-1]\n",
        "    },\n",
        "    {\n",
        "        'outputs': answers[:, 1:]\n",
        "    },\n",
        "))\n",
        "\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)\n",
        "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIsk6mksaVwj"
      },
      "source": [
        "## Training our Transformer\n",
        "\n",
        "Now that we've done all the hard work of setting up and building our model, let's actually train it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4FjRqvDabMv"
      },
      "source": [
        "###Initializing our model\n",
        "\n",
        "First, we must initialize our Transformer object.\n",
        "\n",
        "**Exercise**: Use our Transformer model above to create a Transformer object with these six parameters: \n",
        "1. vocab_size = `VOCAB_SIZE` (we've defined this variable earlier, so you can use the variable name as is)\n",
        "2. num_layers = 2\n",
        "3. units = 512\n",
        "4. d_model = 256\n",
        "5. num_heads = 8\n",
        "6. dropout = 0.1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eY67bx0j4Mf"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "model = None ## YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVRbcgolbDqY",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to initiallize our loss function and learning rate\n",
        "\n",
        "def loss_function(y_true, y_pred):\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  \n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction='none')(y_true, y_pred)\n",
        "\n",
        "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
        "  loss = tf.multiply(loss, mask)\n",
        "\n",
        "  return tf.reduce_mean(loss)\n",
        "\n",
        "\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "\n",
        "  def __init__(self, d_model, warmup_steps=4000):\n",
        "    super(CustomSchedule, self).__init__()\n",
        "\n",
        "    self.d_model = d_model\n",
        "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "    self.warmup_steps = warmup_steps\n",
        "\n",
        "  def __call__(self, step):\n",
        "    arg1 = tf.math.rsqrt(step)\n",
        "    arg2 = step * (self.warmup_steps**-1.5)\n",
        "\n",
        "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "# example of how we can adjust learning rate\n",
        "#sample_learning_rate = CustomSchedule(d_model=128)\n",
        "\n",
        "#plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
        "#plt.ylabel(\"Learning Rate\")\n",
        "#plt.xlabel(\"Train Step\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6gBvdLBkNTV",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to compile our model\n",
        "learning_rate = CustomSchedule(D_MODEL)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(\n",
        "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
        "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
        "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uuu8gLBfcNSp"
      },
      "source": [
        "###Fitting our data\n",
        "\n",
        "**Exercise**: We will now train the model we built on Colab's free GPU! You should train your model for 20 epochs.\n",
        "\n",
        "**Note: BUT, once it starts working, stop the code chunk!** You'll know that it works when you see a progress bar starting with `Epoch 1/20`.\n",
        "\n",
        "Why are we ending early? Our model isn't even close to done training; however, actually training our model would take *waaaaay* too long for our class. For reference, if we were to train the GPT-3 transformer-based model on the most powerful GPU in the world, then [it would still take *355 years* to train](https://lambdalabs.com/blog/demystifying-gpt-3/#1)! Quite a long class period!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_UnprRgb5fy"
      },
      "source": [
        "## YOUR CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdDx0756cQre"
      },
      "source": [
        "So... do we just end here? Well, we just so happen to have a version of this model that was trained on this same data. So we'll evaluate that instead!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "womlk5KiciwH",
        "cellView": "form"
      },
      "source": [
        "#@title Run this cell to import our pretrained model\n",
        "#### TODO: Include path to .h5 file \n",
        "\n",
        "model.load_weights(\"chatbot_transformer_v4.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHjd1CTNcgls"
      },
      "source": [
        "###Evaluating our model\n",
        "\n",
        "Now that we have a working model, let's start playing around with it and see how it does!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK_yXbWFcix7",
        "cellView": "form"
      },
      "source": [
        "#@title Run this code chunk to get the functions that we'll need for this section!\n",
        "def evaluate(sentence):\n",
        "  sentence = preprocess_text(sentence)\n",
        "\n",
        "  sentence = tf.expand_dims(\n",
        "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
        "\n",
        "  output = tf.expand_dims(START_TOKEN, 0)\n",
        "\n",
        "  for i in range(MAX_LENGTH):\n",
        "    predictions = model(inputs=[sentence, output], training=False)\n",
        "\n",
        "    # select the last word from the seq_len dimension\n",
        "    predictions = predictions[:, -1:, :]\n",
        "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "    # return the result if the predicted_id is equal to the end token\n",
        "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
        "      break\n",
        "\n",
        "    # concatenated the predicted_id to the output which is given to the decoder\n",
        "    # as its input.\n",
        "    output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "  return tf.squeeze(output, axis=0)\n",
        "\n",
        "\n",
        "def predict(sentence):\n",
        "  prediction = evaluate(sentence)\n",
        "\n",
        "  predicted_sentence = tokenizer.decode(\n",
        "      [i for i in prediction if i < tokenizer.vocab_size])\n",
        "\n",
        "  print('Input: {}'.format(sentence))\n",
        "  print('Output: {}'.format(predicted_sentence))\n",
        "\n",
        "  return predicted_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u5jIWz0d4nz"
      },
      "source": [
        "###Testing the Transformer's performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pT_-L5PleMWM"
      },
      "source": [
        "Let's tell our program something and see what it says"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2NgvQVkd3v9",
        "cellView": "form"
      },
      "source": [
        "#@title Type in a phrase and let's see what our mental health chatbot thinks!\n",
        "\n",
        "sentence = \"What will make me happy?\" #@param {type:\"string\"}\n",
        "print(\"--------------------\")\n",
        "#output = predict(sentence)\n",
        "predict(sentence)\n",
        "print(\"--------------------\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1qpg7RLIMe8"
      },
      "source": [
        "###Discussion\n",
        "\n",
        "1. How did our model do? Do you think it does better on certain inputs than others?\n",
        "2. Try typing in one sentence, then replacing one word in that sentence, and look at how the output changes. For example, try running\n",
        "\n",
        "  `I'm feeling very happy today`\n",
        "\n",
        "  and then\n",
        "\n",
        "  `I'm feeling very sad today`\n",
        "\n",
        "  See how your model does when you change just one word. Does this surprise you?\n",
        "\n",
        "3. Does this chatbot sound more conversational than our previous chatbots? Is it \"good enough\" or do you think there's room for improvement?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PRdlhvMex_K"
      },
      "source": [
        "###Transfer Learning\n",
        "\n",
        "One flaw in our design above is that we are training our model on a relatively small set of conversations. Because of that, our program has only been exposed to just a small sample of the questions it could ever receive. \n",
        "\n",
        "One way to improve our chatbot is to use a machine learning program that's already been built by someone else, using millions and millions of conversations, and teaching that program to be sensitive to mental health questions. \n",
        "\n",
        "This is called **transfer learning**, which is the process of using a pre-trained model to solve a new question. In this case, we'll use a powerful machine learning program called BERT (Bidirectional Encoder Representations from Transformers) which leverages the same Transformer architecture that we learned about before, but was trained on much more data. \n",
        "\n",
        "**TODO: Do transfer learning with BERT**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxSrojMAsJFr"
      },
      "source": [
        "###Woebot Revisited\n",
        "\n",
        "Now, let's revisit *Woebot*, the mental health chatbot who served as an inspiration for our project!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-SFRfiOC1m4",
        "cellView": "form"
      },
      "source": [
        "#@title Run this to watch a YouTube video describing how Woebot works!\n",
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('Ym5-e4E6Saw')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkvQBcBxDLGl"
      },
      "source": [
        "As you can hopefully see, our chatbot is well on our way to looking more and more like Woebot! With some more work, you'll be able to make an app like Woebot as well, using many of the concepts and principles that we've talked about in this project!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJSrycp7Hdov"
      },
      "source": [
        "##Where do we go from here?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObNgGYQQmm79"
      },
      "source": [
        "Congratulations! You've gotten a little bit of experience now in creating a mental health chatbot. You've learned about how we can leverage the power of NLP to create a program that can talk with someone and provide them with a constant companion. Where do we go from here?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba59rlmxm9S1"
      },
      "source": [
        "Here are some possible suggestions to talk about:\n",
        "\n",
        "1. More data: any AI/ML algorithm does better when it's given more training data. \n",
        "  - Where could we get more data? \n",
        "  - How much more data do we need? \n",
        "\n",
        "2. Can we modify our program to make it better? If so, how so?\n",
        "  - Could we perhaps combine our machine learning based method with some rules?\n",
        "  - Do we want our program to, say, be able to send the user to mental health resources or be able to contact live mental health professionals?\n",
        "\n",
        "3. What do you think are some of the ethical implications of these chatbots?\n",
        "  - What happens if our chatbot says something discouraging and just causes someone to feel worse?\n",
        "  - Should our program be trying to give advice to users or is it more of a companion that just provides an ear to talk to?\n",
        "  - Chatbots in the news: [A Bot Went on Twitter, Talked with People About Things Like Suicide](https://www.technologyreview.com/2020/10/08/1009845/a-gpt-3-bot-posted-comments-on-reddit-for-a-week-and-no-one-noticed/)\n",
        "\n",
        "4. What do we do with the program that we just created? \n",
        "  - Turn it into an app! Look into deploying the pretrained model that you used today. For example, you can use Flask/Django to create a web app where you give people a text box where they can type in questions and talk to our new chatbot. \n",
        "  - Use this same technology, but for something else! We created a chatbot in the context of mental health, but as you've seen, there's chatbots for many types of applications, so get creative! If you like sports, maybe create a chatbot that'll give you the stats of your favorite player. If you want a study buddy, maybe create a chatbot that can read the same material that you're studying and quiz you on the material. If you just like hearing yourself talk, take all your texts, WeChat messages, WhatsApp conversations, and everything else in between, feed that into a chatbot, and train it to talk just like yourself! As you can see, the possibilities are limitless!\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxwu4tbTlcWp"
      },
      "source": [
        "##Conclusion\n",
        "\n",
        "During this deep dive, you've gained an introduction into how we can create chatbots using AI and machine learning. You first began by learning about rule-based approaches, where we have to write every single phrase that a chatbot could hear and then design an appropriate response for each. We saw how that was inefficient, so we discussed how machine learning, specifically deep learning and neural networks, can be used to create a chatbot with a richer understanding of language. Finally, in this notebook, we experimented with some of the current state-of-the-art NLP algorithms, specifically Transformers, and we learned about how they can be used to create a more conversational chatbot. You've learned so much over the course of this project and have reviewed some very advanced topics, which will hopefully fuel your growth as you start your career in AI and machine learning! Happy coding!"
      ]
    }
  ]
}